{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics\n",
    "import os\n",
    "os.environ['TF_CPP_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets train: (50000, 32, 32, 3) (50000, 10) 0 255\n",
      "datasets validate: (10000, 32, 32, 3) (10000, 10) 0 255\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x,y):\n",
    "    \"\"\" \n",
    "    x is a simple imges,not a batch, 32*32*3\n",
    "    \"\"\"\n",
    "    #[0 255]->[0,1]->[-1,1]\n",
    "    x=2*tf.cast(x,dtype=tf.float32)/255.-1\n",
    "    y=tf.cast(y,dtype=tf.int32)\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "batchsz=128\n",
    "(x,y),(x_val,y_val)=datasets.cifar10.load_data()\n",
    "# y 是[50k,1] -> 50k\n",
    "y=tf.squeeze(y)\n",
    "y_val=tf.squeeze(y_val)\n",
    "\n",
    "y=tf.one_hot(y,depth=10)\n",
    "y_val=tf.one_hot(y_val,depth=10)\n",
    "\n",
    "print('datasets train:',x.shape,y.shape,x.min(),x.max())\n",
    "print('datasets validate:',x_val.shape,y_val.shape,x_val.min(),x_val.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampel batch: (128, 32, 32, 3) (128, 10)\n"
     ]
    }
   ],
   "source": [
    "# 构建数据集\n",
    "train_db=tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_db=train_db.map(preprocess).shuffle(10000).batch(batchsz)\n",
    "\n",
    "val_db=tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "val_db=val_db.map(preprocess).batch(batchsz)\n",
    "\n",
    "sample=next(iter(train_db))\n",
    "print('sampel batch:',sample[0].shape,sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(layers.Layer):\n",
    "    # to replace standard layers.Dense()\n",
    "    def __init__(self,inp_dim,outp_dim):\n",
    "        super(MyDense,self).__init__()\n",
    "    \n",
    "        self.kernal=self.add_weight('w',[inp_dim,outp_dim])\n",
    "        #self.bias=self.add_weight('b',outp_dim) # 故意去掉bias\n",
    "    \n",
    "    def call(self,inputs,training=None):\n",
    "        x=inputs@self.kernal\n",
    "        return x\n",
    "    \n",
    "class MyNetwork(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyNetwork,self).__init__()\n",
    "        self.fc1=MyDense(32*32*3,256)\n",
    "        self.fc2=MyDense(256,128)\n",
    "        self.fc3=MyDense(128,64)\n",
    "        self.fc4=MyDense(64,32)\n",
    "        self.fc5=MyDense(32,10)\n",
    "        \n",
    "    def call(self,inputs,training=None):\n",
    "        \"\"\"\n",
    "        :param input: b,32,32,3\n",
    "        :param training:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x=tf.reshape(inputs,[-1,32*32*3])\n",
    "        #[b,32*32*3]->[b,256]->[b,128]->[b,64]->[b,32]->[b,10]\n",
    "        x=self.fc1(x)\n",
    "        x=tf.nn.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        x=tf.nn.relu(x)\n",
    "        x=self.fc3(x)\n",
    "        x=tf.nn.relu(x)\n",
    "        x=self.fc4(x)\n",
    "        x=tf.nn.relu(x)\n",
    "        x=self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 391 steps, validate for 79 steps\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1.7155 - accuracy: 0.3939 - val_loss: 1.5777 - val_accuracy: 0.4363\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.4949 - accuracy: 0.4734 - val_loss: 1.4836 - val_accuracy: 0.4837\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.3928 - accuracy: 0.5084 - val_loss: 1.4453 - val_accuracy: 0.4981\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1.3151 - accuracy: 0.5385 - val_loss: 1.4149 - val_accuracy: 0.5009\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 1.2416 - accuracy: 0.5639 - val_loss: 1.4137 - val_accuracy: 0.5083\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 1.1779 - accuracy: 0.5857 - val_loss: 1.4050 - val_accuracy: 0.5188\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 1.1180 - accuracy: 0.6065 - val_loss: 1.3824 - val_accuracy: 0.5199\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 1.0599 - accuracy: 0.6237 - val_loss: 1.4229 - val_accuracy: 0.5192\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.0066 - accuracy: 0.6444 - val_loss: 1.4424 - val_accuracy: 0.5160\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.9613 - accuracy: 0.6607 - val_loss: 1.4688 - val_accuracy: 0.5200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23bc5051a88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network=MyNetwork()\n",
    "network.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "               loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy']\n",
    "               )\n",
    "network.fit(train_db,epochs=10,validation_data=val_db,validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 20ms/step - loss: 1.4688 - accuracy: 0.5200\n",
      "saved the weights\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 1.4688 - accuracy: 0.5200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4688046265252028, 0.52]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(val_db)\n",
    "network.save_weights('ckpt/saved_weights')\n",
    "del network\n",
    "print('saved the weights')\n",
    "\n",
    "network=MyNetwork()\n",
    "network.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "               loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy']\n",
    "               )\n",
    "network.load_weights('ckpt/saved_weights')\n",
    "network.evaluate(val_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
